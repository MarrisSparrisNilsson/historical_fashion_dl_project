{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d070e48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 SUPER, compute capability 8.9\n",
      "Label mean year = 1845.86, std = 16.43\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet101, NASNetMobile, InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "DATA_DIR   = r'C:/Users/maxim/Documents/DLProjectDress/datasets'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS     = 5\n",
    "LR         = 1e-4\n",
    "INPUT_SIZE = (224, 224)\n",
    "\n",
    "# compute global mean & std of the 'year' label\n",
    "all_dfs = [pd.read_csv(os.path.join(DATA_DIR, f'fold{i}.csv'))\n",
    "           for i in range(10)]\n",
    "df_all  = pd.concat(all_dfs, ignore_index=True)\n",
    "YEAR_MEAN = df_all['year'].mean()\n",
    "YEAR_STD  = df_all['year'].std()\n",
    "print(f'Label mean year = {YEAR_MEAN:.2f}, std = {YEAR_STD:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f743d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3643dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, label, training):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, INPUT_SIZE)\n",
    "    if training:\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "    img = img / 255.0\n",
    "\n",
    "    # normalize the year label to zero‐mean, unit‐std\n",
    "    label = (label - YEAR_MEAN) / YEAR_STD\n",
    "    return img, tf.cast(label, tf.float32)\n",
    "\n",
    "def make_dataset(df, training):\n",
    "    df = df.copy()\n",
    "    #df['file'] = df['file'].str.replace(r'^datasets[\\\\/]', '', regex=True)\n",
    "\n",
    "    files  = [os.path.join(DATA_DIR, p) for p in df['file']]\n",
    "    labels = df['year'].values\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((files, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(files))\n",
    "    ds = ds.map(lambda x,y: preprocess(x,y,training),\n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(name, base, input_shape=(*INPUT_SIZE, 3), lr=LR):\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    out = Dense(1)(x)   # regression head\n",
    "\n",
    "    model = Model(base.input, out)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer=Adam(lr), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a01992",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['resnet101','nasnetmobile','inceptionv3']\n",
    "results = {m: [] for m in models}\n",
    "\n",
    "for model_name in models:\n",
    "    if model_name == 'resnet101':\n",
    "        base = ResNet101(include_top=False, weights='imagenet',\n",
    "                         input_shape=(*INPUT_SIZE, 3))\n",
    "    elif model_name == 'nasnetmobile':\n",
    "        base = NASNetMobile(include_top=False, weights='imagenet',\n",
    "                            input_shape=(*INPUT_SIZE, 3))\n",
    "    elif model_name == 'inceptionv3':\n",
    "        base = InceptionV3(include_top=False, weights='imagenet',\n",
    "                           input_shape=(*INPUT_SIZE, 3))\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model: {model_name}')\n",
    "    \n",
    "    print(base.summary())\n",
    "    print(f'\\n=== {model_name} ===')\n",
    "    for fold in range(10):\n",
    "        # Load the CSVs from DATA_DIR\n",
    "        val_df   = pd.read_csv(os.path.join(DATA_DIR, f'fold{fold}.csv'))\n",
    "        train_df = pd.concat([\n",
    "            pd.read_csv(os.path.join(DATA_DIR, f'fold{i}.csv'))\n",
    "            for i in range(10) if i != fold\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        # Strip leading 'datasets/' so paths are RELATIVE to DATA_DIR\n",
    "        for df in (train_df, val_df):\n",
    "            df['file'] = df['file'].str.replace(\n",
    "                r'^datasets[\\\\/]', '', regex=True\n",
    "            )\n",
    "\n",
    "        # Build tf.data pipelines\n",
    "        train_ds = make_dataset(train_df, training=True)\n",
    "        val_ds   = make_dataset(val_df,   training=False)\n",
    "\n",
    "        # Train & checkpoint\n",
    "        model = build_model(model_name)\n",
    "        ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "            f'{model_name}_fold{fold}.h5',\n",
    "            monitor='val_loss', save_best_only=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2ae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== resnet101 ===\n",
      "Epoch 1/5\n",
      "354/354 - 69s - loss: 0.3030 - mae: 0.4158 - val_loss: 1.1235 - val_mae: 0.8942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 52s - loss: 0.1065 - mae: 0.2489 - val_loss: 0.5241 - val_mae: 0.5791\n",
      "Epoch 3/5\n",
      "354/354 - 51s - loss: 0.0602 - mae: 0.1869 - val_loss: 0.2199 - val_mae: 0.3517\n",
      "Epoch 4/5\n",
      "354/354 - 53s - loss: 0.0420 - mae: 0.1543 - val_loss: 0.0814 - val_mae: 0.1921\n",
      "Epoch 5/5\n",
      "354/354 - 52s - loss: 0.0343 - mae: 0.1391 - val_loss: 0.0758 - val_mae: 0.1860\n",
      " Fold 0 → best val_mse: 0.0758\n",
      "Epoch 1/5\n",
      "354/354 - 62s - loss: 0.3625 - mae: 0.4466 - val_loss: 1.0310 - val_mae: 0.8876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 51s - loss: 0.1108 - mae: 0.2542 - val_loss: 0.4861 - val_mae: 0.5557\n",
      "Epoch 3/5\n",
      "354/354 - 51s - loss: 0.0623 - mae: 0.1895 - val_loss: 0.1719 - val_mae: 0.3004\n",
      "Epoch 4/5\n",
      "354/354 - 51s - loss: 0.0476 - mae: 0.1632 - val_loss: 0.1048 - val_mae: 0.2373\n",
      "Epoch 5/5\n",
      "354/354 - 51s - loss: 0.0373 - mae: 0.1446 - val_loss: 0.0969 - val_mae: 0.2097\n",
      " Fold 1 → best val_mse: 0.0969\n",
      "Epoch 1/5\n",
      "354/354 - 64s - loss: 0.3170 - mae: 0.4295 - val_loss: 1.0441 - val_mae: 0.9052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 53s - loss: 0.1221 - mae: 0.2666 - val_loss: 0.6624 - val_mae: 0.6638\n",
      "Epoch 3/5\n",
      "354/354 - 52s - loss: 0.0752 - mae: 0.2085 - val_loss: 0.1911 - val_mae: 0.3284\n",
      "Epoch 4/5\n",
      "354/354 - 52s - loss: 0.0448 - mae: 0.1591 - val_loss: 0.0761 - val_mae: 0.1972\n",
      "Epoch 5/5\n",
      "354/354 - 54s - loss: 0.0364 - mae: 0.1446 - val_loss: 0.0738 - val_mae: 0.1918\n",
      " Fold 2 → best val_mse: 0.0738\n",
      "Epoch 1/5\n",
      "354/354 - 67s - loss: 0.3043 - mae: 0.4101 - val_loss: 1.0738 - val_mae: 0.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 54s - loss: 0.1030 - mae: 0.2431 - val_loss: 0.5530 - val_mae: 0.6287\n",
      "Epoch 3/5\n",
      "354/354 - 53s - loss: 0.0624 - mae: 0.1894 - val_loss: 0.2173 - val_mae: 0.3518\n",
      "Epoch 4/5\n",
      "354/354 - 54s - loss: 0.0433 - mae: 0.1569 - val_loss: 0.0772 - val_mae: 0.2100\n",
      "Epoch 5/5\n",
      "354/354 - 55s - loss: 0.0341 - mae: 0.1385 - val_loss: 0.0989 - val_mae: 0.2286\n",
      " Fold 3 → best val_mse: 0.0772\n",
      "Epoch 1/5\n",
      "354/354 - 66s - loss: 0.2887 - mae: 0.4030 - val_loss: 1.3163 - val_mae: 0.9562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 54s - loss: 0.0984 - mae: 0.2376 - val_loss: 0.4496 - val_mae: 0.5614\n",
      "Epoch 3/5\n",
      "354/354 - 53s - loss: 0.0670 - mae: 0.1947 - val_loss: 0.1592 - val_mae: 0.2974\n",
      "Epoch 4/5\n",
      "354/354 - 54s - loss: 0.0448 - mae: 0.1574 - val_loss: 0.1078 - val_mae: 0.2342\n",
      "Epoch 5/5\n",
      "354/354 - 54s - loss: 0.0341 - mae: 0.1382 - val_loss: 0.0869 - val_mae: 0.1938\n",
      " Fold 4 → best val_mse: 0.0869\n",
      "Epoch 1/5\n",
      "354/354 - 67s - loss: 0.3171 - mae: 0.4188 - val_loss: 1.1289 - val_mae: 0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 55s - loss: 0.1051 - mae: 0.2437 - val_loss: 0.5270 - val_mae: 0.6114\n",
      "Epoch 3/5\n",
      "354/354 - 54s - loss: 0.0610 - mae: 0.1864 - val_loss: 0.2036 - val_mae: 0.3442\n",
      "Epoch 4/5\n",
      "354/354 - 53s - loss: 0.0423 - mae: 0.1543 - val_loss: 0.0708 - val_mae: 0.1957\n",
      "Epoch 5/5\n",
      "354/354 - 51s - loss: 0.0344 - mae: 0.1376 - val_loss: 0.0761 - val_mae: 0.2013\n",
      " Fold 5 → best val_mse: 0.0708\n",
      "Epoch 1/5\n",
      "354/354 - 67s - loss: 0.3161 - mae: 0.4239 - val_loss: 0.9503 - val_mae: 0.8436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 56s - loss: 0.1124 - mae: 0.2553 - val_loss: 0.4660 - val_mae: 0.5519\n",
      "Epoch 3/5\n",
      "354/354 - 55s - loss: 0.0636 - mae: 0.1919 - val_loss: 0.2155 - val_mae: 0.3556\n",
      "Epoch 4/5\n",
      "354/354 - 55s - loss: 0.0442 - mae: 0.1582 - val_loss: 0.0855 - val_mae: 0.1984\n",
      "Epoch 5/5\n",
      "354/354 - 55s - loss: 0.0359 - mae: 0.1418 - val_loss: 0.0871 - val_mae: 0.2040\n",
      " Fold 6 → best val_mse: 0.0855\n",
      "Epoch 1/5\n",
      "354/354 - 68s - loss: 0.3077 - mae: 0.4221 - val_loss: 7.2023 - val_mae: 2.4106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 54s - loss: 0.1027 - mae: 0.2406 - val_loss: 0.5258 - val_mae: 0.5928\n",
      "Epoch 3/5\n",
      "354/354 - 55s - loss: 0.0596 - mae: 0.1863 - val_loss: 0.1309 - val_mae: 0.2698\n",
      "Epoch 4/5\n",
      "354/354 - 55s - loss: 0.0457 - mae: 0.1602 - val_loss: 0.1027 - val_mae: 0.2411\n",
      "Epoch 5/5\n",
      "354/354 - 55s - loss: 0.0383 - mae: 0.1481 - val_loss: 0.0827 - val_mae: 0.1957\n",
      " Fold 7 → best val_mse: 0.0827\n",
      "Epoch 1/5\n",
      "354/354 - 69s - loss: 0.3107 - mae: 0.4234 - val_loss: 1.1644 - val_mae: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 52s - loss: 0.1095 - mae: 0.2515 - val_loss: 1.0484 - val_mae: 0.8356\n",
      "Epoch 3/5\n",
      "354/354 - 54s - loss: 0.0590 - mae: 0.1857 - val_loss: 0.2046 - val_mae: 0.3210\n",
      "Epoch 4/5\n",
      "354/354 - 54s - loss: 0.0474 - mae: 0.1646 - val_loss: 0.1235 - val_mae: 0.2613\n",
      "Epoch 5/5\n",
      "354/354 - 54s - loss: 0.0359 - mae: 0.1431 - val_loss: 0.0897 - val_mae: 0.2056\n",
      " Fold 8 → best val_mse: 0.0897\n",
      "Epoch 1/5\n",
      "354/354 - 69s - loss: 0.3149 - mae: 0.4207 - val_loss: 1.0837 - val_mae: 0.9051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 53s - loss: 0.1010 - mae: 0.2414 - val_loss: 0.4860 - val_mae: 0.5509\n",
      "Epoch 3/5\n",
      "354/354 - 54s - loss: 0.0569 - mae: 0.1789 - val_loss: 0.2479 - val_mae: 0.3593\n",
      "Epoch 4/5\n",
      "354/354 - 54s - loss: 0.0418 - mae: 0.1527 - val_loss: 0.0828 - val_mae: 0.2082\n",
      "Epoch 5/5\n",
      "354/354 - 53s - loss: 0.0345 - mae: 0.1389 - val_loss: 0.0819 - val_mae: 0.1997\n",
      " Fold 9 → best val_mse: 0.0819\n",
      "\n",
      "=== nasnetmobile ===\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
      "19996672/19993432 [==============================] - 1s 0us/step\n",
      "20004864/19993432 [==============================] - 1s 0us/step\n",
      "Epoch 1/5\n",
      "354/354 - 71s - loss: 0.2927 - mae: 0.3996 - val_loss: 0.6796 - val_mae: 0.6915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 42s - loss: 0.1115 - mae: 0.2450 - val_loss: 0.4110 - val_mae: 0.5245\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(model_name)\n\u001b[0;32m     26\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     28\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     39\u001b[0m results[model_name]\u001b[38;5;241m.\u001b[39mappend(best)\n",
      "File \u001b[1;32mc:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = ['resnet101','nasnetmobile','inceptionv3']\n",
    "results = {m: [] for m in models}\n",
    "\n",
    "for model_name in models:\n",
    "    print(f'\\n=== {model_name} ===')\n",
    "    for fold in range(10):\n",
    "        # Load the CSVs from DATA_DIR\n",
    "        val_df   = pd.read_csv(os.path.join(DATA_DIR, f'fold{fold}.csv'))\n",
    "        train_df = pd.concat([\n",
    "            pd.read_csv(os.path.join(DATA_DIR, f'fold{i}.csv'))\n",
    "            for i in range(10) if i != fold\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        # Strip leading 'datasets/' so paths are RELATIVE to DATA_DIR\n",
    "        for df in (train_df, val_df):\n",
    "            df['file'] = df['file'].str.replace(\n",
    "                r'^datasets[\\\\/]', '', regex=True\n",
    "            )\n",
    "\n",
    "        # Build tf.data pipelines\n",
    "        train_ds = make_dataset(train_df, training=True)\n",
    "        val_ds   = make_dataset(val_df,   training=False)\n",
    "\n",
    "        # Train & checkpoint\n",
    "        model = build_model(model_name)\n",
    "        ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "            f'{model_name}_fold{fold}.h5',\n",
    "            monitor='val_loss', save_best_only=True\n",
    "        )\n",
    "        hist = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[ckpt],\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        best = min(hist.history['val_loss'])\n",
    "        results[model_name].append(best)\n",
    "        print(f' Fold {fold} → best val_mse: {best:.4f}')\n",
    "\n",
    "print('\\nCV MSE per model:')\n",
    "for m, vals in results.items():\n",
    "    print(f' {m}:', [f'{v:.4f}' for v in vals])\n",
    "\n",
    "pd.DataFrame(results).to_csv('cv_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeba19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== nasnetmobile ===\n",
      "Epoch 1/5\n",
      "354/354 - 79s - loss: 0.2656 - mae: 0.3762 - val_loss: 0.6058 - val_mae: 0.6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 46s - loss: 0.1063 - mae: 0.2361 - val_loss: 0.3450 - val_mae: 0.4547\n",
      "Epoch 3/5\n",
      "354/354 - 46s - loss: 0.0654 - mae: 0.1865 - val_loss: 0.2753 - val_mae: 0.3887\n",
      "Epoch 4/5\n",
      "354/354 - 46s - loss: 0.0485 - mae: 0.1630 - val_loss: 0.1995 - val_mae: 0.3276\n",
      "Epoch 5/5\n",
      "354/354 - 46s - loss: 0.0372 - mae: 0.1444 - val_loss: 0.2323 - val_mae: 0.3513\n",
      " Fold 0 → best normalized-MSE: 0.1995\n",
      "Epoch 1/5\n",
      "354/354 - 71s - loss: 0.2906 - mae: 0.3935 - val_loss: 0.5012 - val_mae: 0.5421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 45s - loss: 0.1134 - mae: 0.2441 - val_loss: 0.3946 - val_mae: 0.4710\n",
      "Epoch 3/5\n",
      "354/354 - 45s - loss: 0.0730 - mae: 0.1997 - val_loss: 0.3083 - val_mae: 0.4120\n",
      "Epoch 4/5\n",
      "354/354 - 45s - loss: 0.0521 - mae: 0.1694 - val_loss: 0.2653 - val_mae: 0.3833\n",
      "Epoch 5/5\n",
      "354/354 - 45s - loss: 0.0411 - mae: 0.1506 - val_loss: 0.1995 - val_mae: 0.3360\n",
      " Fold 1 → best normalized-MSE: 0.1995\n",
      "Epoch 1/5\n",
      "354/354 - 74s - loss: 0.2694 - mae: 0.3783 - val_loss: 0.5720 - val_mae: 0.5720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 46s - loss: 0.1090 - mae: 0.2376 - val_loss: 0.2602 - val_mae: 0.3761\n",
      "Epoch 3/5\n",
      "354/354 - 46s - loss: 0.0670 - mae: 0.1884 - val_loss: 0.1945 - val_mae: 0.3338\n",
      "Epoch 4/5\n",
      "354/354 - 47s - loss: 0.0496 - mae: 0.1636 - val_loss: 0.1895 - val_mae: 0.3214\n",
      "Epoch 5/5\n",
      "354/354 - 47s - loss: 0.0395 - mae: 0.1465 - val_loss: 0.2425 - val_mae: 0.3661\n",
      " Fold 2 → best normalized-MSE: 0.1895\n",
      "Epoch 1/5\n",
      "354/354 - 73s - loss: 0.2743 - mae: 0.3822 - val_loss: 0.3179 - val_mae: 0.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 46s - loss: 0.1066 - mae: 0.2366 - val_loss: 0.3078 - val_mae: 0.4222\n",
      "Epoch 3/5\n",
      "354/354 - 46s - loss: 0.0710 - mae: 0.1965 - val_loss: 0.2228 - val_mae: 0.3475\n",
      "Epoch 4/5\n",
      "354/354 - 46s - loss: 0.0508 - mae: 0.1664 - val_loss: 0.1413 - val_mae: 0.2747\n",
      "Epoch 5/5\n",
      "354/354 - 46s - loss: 0.0388 - mae: 0.1468 - val_loss: 0.1698 - val_mae: 0.3085\n",
      " Fold 3 → best normalized-MSE: 0.1413\n",
      "Epoch 1/5\n",
      "354/354 - 74s - loss: 0.2742 - mae: 0.3857 - val_loss: 0.7460 - val_mae: 0.6782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 47s - loss: 0.1120 - mae: 0.2465 - val_loss: 0.8815 - val_mae: 0.7448\n",
      "Epoch 3/5\n",
      "354/354 - 46s - loss: 0.0728 - mae: 0.1976 - val_loss: 0.6800 - val_mae: 0.6346\n",
      "Epoch 4/5\n",
      "354/354 - 46s - loss: 0.0510 - mae: 0.1693 - val_loss: 0.4337 - val_mae: 0.4795\n",
      "Epoch 5/5\n",
      "354/354 - 46s - loss: 0.0424 - mae: 0.1537 - val_loss: 0.2150 - val_mae: 0.3266\n",
      " Fold 4 → best normalized-MSE: 0.2150\n",
      "Epoch 1/5\n",
      "354/354 - 73s - loss: 0.2868 - mae: 0.3953 - val_loss: 0.3315 - val_mae: 0.4514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 46s - loss: 0.1097 - mae: 0.2422 - val_loss: 0.3674 - val_mae: 0.4620\n",
      "Epoch 3/5\n",
      "354/354 - 46s - loss: 0.0702 - mae: 0.1951 - val_loss: 0.3175 - val_mae: 0.4083\n",
      "Epoch 4/5\n",
      "354/354 - 46s - loss: 0.0508 - mae: 0.1671 - val_loss: 0.3324 - val_mae: 0.4193\n",
      "Epoch 5/5\n",
      "354/354 - 45s - loss: 0.0399 - mae: 0.1486 - val_loss: 0.3335 - val_mae: 0.4220\n",
      " Fold 5 → best normalized-MSE: 0.3175\n",
      "Epoch 1/5\n",
      "354/354 - 75s - loss: 0.2610 - mae: 0.3743 - val_loss: 0.3830 - val_mae: 0.4786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 47s - loss: 0.1058 - mae: 0.2374 - val_loss: 0.3801 - val_mae: 0.4838\n",
      "Epoch 3/5\n",
      "354/354 - 47s - loss: 0.0655 - mae: 0.1900 - val_loss: 0.3142 - val_mae: 0.4374\n",
      "Epoch 4/5\n",
      "354/354 - 47s - loss: 0.0503 - mae: 0.1655 - val_loss: 0.1785 - val_mae: 0.3124\n",
      "Epoch 5/5\n",
      "354/354 - 47s - loss: 0.0378 - mae: 0.1450 - val_loss: 0.1783 - val_mae: 0.3119\n",
      " Fold 6 → best normalized-MSE: 0.1783\n",
      "Epoch 1/5\n",
      "354/354 - 75s - loss: 0.2869 - mae: 0.3891 - val_loss: 0.3381 - val_mae: 0.4527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 46s - loss: 0.1112 - mae: 0.2439 - val_loss: 0.2555 - val_mae: 0.3896\n",
      "Epoch 3/5\n",
      "354/354 - 46s - loss: 0.0720 - mae: 0.1974 - val_loss: 0.2315 - val_mae: 0.3707\n",
      "Epoch 4/5\n",
      "354/354 - 46s - loss: 0.0502 - mae: 0.1664 - val_loss: 0.2370 - val_mae: 0.3719\n",
      "Epoch 5/5\n",
      "354/354 - 47s - loss: 0.0415 - mae: 0.1523 - val_loss: 0.2286 - val_mae: 0.3574\n",
      " Fold 7 → best normalized-MSE: 0.2286\n",
      "Epoch 1/5\n",
      "354/354 - 74s - loss: 0.2782 - mae: 0.3828 - val_loss: 0.7233 - val_mae: 0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 47s - loss: 0.1096 - mae: 0.2425 - val_loss: 0.3435 - val_mae: 0.4588\n",
      "Epoch 3/5\n",
      "354/354 - 47s - loss: 0.0719 - mae: 0.1965 - val_loss: 0.3781 - val_mae: 0.4860\n",
      "Epoch 4/5\n",
      "354/354 - 47s - loss: 0.0519 - mae: 0.1692 - val_loss: 0.2823 - val_mae: 0.4101\n",
      "Epoch 5/5\n",
      "354/354 - 47s - loss: 0.0400 - mae: 0.1482 - val_loss: 0.2266 - val_mae: 0.3604\n",
      " Fold 8 → best normalized-MSE: 0.2266\n",
      "Epoch 1/5\n",
      "354/354 - 74s - loss: 0.2773 - mae: 0.3869 - val_loss: 0.9937 - val_mae: 0.8631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\deep_learning_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "354/354 - 46s - loss: 0.1110 - mae: 0.2427 - val_loss: 0.4786 - val_mae: 0.5696\n",
      "Epoch 3/5\n",
      "354/354 - 46s - loss: 0.0716 - mae: 0.1975 - val_loss: 0.2831 - val_mae: 0.3997\n",
      "Epoch 4/5\n",
      "354/354 - 47s - loss: 0.0515 - mae: 0.1684 - val_loss: 0.2899 - val_mae: 0.4171\n",
      "Epoch 5/5\n",
      "354/354 - 46s - loss: 0.0390 - mae: 0.1475 - val_loss: 0.2571 - val_mae: 0.3840\n",
      " Fold 9 → best normalized-MSE: 0.2571\n",
      "\n",
      "=== inceptionv3 ===\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 3s 0us/step\n",
      "87924736/87910968 [==============================] - 3s 0us/step\n",
      "Epoch 1/5\n",
      "354/354 - 45s - loss: 0.2594 - mae: 0.3766 - val_loss: 0.1267 - val_mae: 0.2540\n",
      "Epoch 2/5\n",
      "354/354 - 31s - loss: 0.1147 - mae: 0.2531 - val_loss: 0.1401 - val_mae: 0.2765\n",
      "Epoch 3/5\n",
      "354/354 - 31s - loss: 0.0775 - mae: 0.2087 - val_loss: 0.0816 - val_mae: 0.1984\n",
      "Epoch 4/5\n",
      "354/354 - 31s - loss: 0.0539 - mae: 0.1727 - val_loss: 0.0862 - val_mae: 0.2054\n",
      "Epoch 5/5\n",
      "354/354 - 31s - loss: 0.0405 - mae: 0.1509 - val_loss: 0.0953 - val_mae: 0.2106\n",
      " Fold 0 → best normalized-MSE: 0.0816\n",
      "Epoch 1/5\n",
      "354/354 - 39s - loss: 0.2800 - mae: 0.3933 - val_loss: 0.1432 - val_mae: 0.2718\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1174 - mae: 0.2535 - val_loss: 0.1516 - val_mae: 0.3016\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0774 - mae: 0.2070 - val_loss: 0.0943 - val_mae: 0.2130\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0568 - mae: 0.1770 - val_loss: 0.0876 - val_mae: 0.2085\n",
      "Epoch 5/5\n",
      "354/354 - 31s - loss: 0.0473 - mae: 0.1626 - val_loss: 0.0725 - val_mae: 0.1814\n",
      " Fold 1 → best normalized-MSE: 0.0725\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2789 - mae: 0.3949 - val_loss: 0.1325 - val_mae: 0.2792\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1171 - mae: 0.2535 - val_loss: 0.0865 - val_mae: 0.2160\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0772 - mae: 0.2065 - val_loss: 0.0810 - val_mae: 0.2066\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0538 - mae: 0.1736 - val_loss: 0.0723 - val_mae: 0.1851\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0406 - mae: 0.1506 - val_loss: 0.0862 - val_mae: 0.2057\n",
      " Fold 2 → best normalized-MSE: 0.0723\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2588 - mae: 0.3773 - val_loss: 0.1373 - val_mae: 0.2747\n",
      "Epoch 2/5\n",
      "354/354 - 31s - loss: 0.1088 - mae: 0.2419 - val_loss: 0.0946 - val_mae: 0.2227\n",
      "Epoch 3/5\n",
      "354/354 - 31s - loss: 0.0690 - mae: 0.1940 - val_loss: 0.0691 - val_mae: 0.1904\n",
      "Epoch 4/5\n",
      "354/354 - 31s - loss: 0.0545 - mae: 0.1707 - val_loss: 0.0650 - val_mae: 0.1874\n",
      "Epoch 5/5\n",
      "354/354 - 31s - loss: 0.0402 - mae: 0.1484 - val_loss: 0.0530 - val_mae: 0.1650\n",
      " Fold 3 → best normalized-MSE: 0.0530\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2655 - mae: 0.3793 - val_loss: 0.1752 - val_mae: 0.3169\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1089 - mae: 0.2456 - val_loss: 0.1019 - val_mae: 0.2307\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0726 - mae: 0.2017 - val_loss: 0.0941 - val_mae: 0.2114\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0501 - mae: 0.1673 - val_loss: 0.0885 - val_mae: 0.1996\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0409 - mae: 0.1512 - val_loss: 0.0795 - val_mae: 0.1885\n",
      " Fold 4 → best normalized-MSE: 0.0795\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2647 - mae: 0.3845 - val_loss: 0.1382 - val_mae: 0.2748\n",
      "Epoch 2/5\n",
      "354/354 - 31s - loss: 0.1219 - mae: 0.2622 - val_loss: 0.0883 - val_mae: 0.2170\n",
      "Epoch 3/5\n",
      "354/354 - 31s - loss: 0.0797 - mae: 0.2104 - val_loss: 0.0849 - val_mae: 0.2148\n",
      "Epoch 4/5\n",
      "354/354 - 31s - loss: 0.0570 - mae: 0.1783 - val_loss: 0.0673 - val_mae: 0.1845\n",
      "Epoch 5/5\n",
      "354/354 - 31s - loss: 0.0444 - mae: 0.1572 - val_loss: 0.0653 - val_mae: 0.1840\n",
      " Fold 5 → best normalized-MSE: 0.0653\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2584 - mae: 0.3778 - val_loss: 0.1332 - val_mae: 0.2665\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1217 - mae: 0.2614 - val_loss: 0.1051 - val_mae: 0.2345\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0720 - mae: 0.1995 - val_loss: 0.0876 - val_mae: 0.2086\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0498 - mae: 0.1675 - val_loss: 0.0818 - val_mae: 0.1984\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0382 - mae: 0.1460 - val_loss: 0.0766 - val_mae: 0.1848\n",
      " Fold 6 → best normalized-MSE: 0.0766\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2682 - mae: 0.3876 - val_loss: 0.1415 - val_mae: 0.2769\n",
      "Epoch 2/5\n",
      "354/354 - 31s - loss: 0.1211 - mae: 0.2610 - val_loss: 0.1179 - val_mae: 0.2400\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0815 - mae: 0.2118 - val_loss: 0.1046 - val_mae: 0.2275\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0573 - mae: 0.1782 - val_loss: 0.0954 - val_mae: 0.1999\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0424 - mae: 0.1540 - val_loss: 0.0863 - val_mae: 0.1898\n",
      " Fold 7 → best normalized-MSE: 0.0863\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2638 - mae: 0.3813 - val_loss: 0.1367 - val_mae: 0.2682\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1121 - mae: 0.2480 - val_loss: 0.1174 - val_mae: 0.2440\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0712 - mae: 0.1996 - val_loss: 0.0945 - val_mae: 0.2077\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0519 - mae: 0.1709 - val_loss: 0.0875 - val_mae: 0.1906\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0391 - mae: 0.1472 - val_loss: 0.0919 - val_mae: 0.1930\n",
      " Fold 8 → best normalized-MSE: 0.0875\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2667 - mae: 0.3826 - val_loss: 0.2744 - val_mae: 0.3989\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1139 - mae: 0.2509 - val_loss: 0.0929 - val_mae: 0.2172\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0740 - mae: 0.2028 - val_loss: 0.0883 - val_mae: 0.2094\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0509 - mae: 0.1701 - val_loss: 0.0939 - val_mae: 0.2077\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0396 - mae: 0.1481 - val_loss: 0.0841 - val_mae: 0.2122\n",
      " Fold 9 → best normalized-MSE: 0.0841\n",
      "\n",
      "CV normalized-MSE for remaining models:\n",
      " nasnetmobile: ['0.1995', '0.1995', '0.1895', '0.1413', '0.2150', '0.3175', '0.1783', '0.2286', '0.2266', '0.2571']\n",
      " inceptionv3: ['0.0816', '0.0725', '0.0723', '0.0530', '0.0795', '0.0653', '0.0766', '0.0863', '0.0875', '0.0841']\n"
     ]
    }
   ],
   "source": [
    "# Only run the remaining models\n",
    "models = ['nasnetmobile','inceptionv3']\n",
    "results_other = {m: [] for m in models}\n",
    "\n",
    "for model_name in models:\n",
    "    print(f'\\n=== {model_name} ===')\n",
    "    for fold in range(10):\n",
    "        val_df = pd.read_csv(os.path.join(DATA_DIR, f'fold{fold}.csv'))\n",
    "        train_df = pd.concat([\n",
    "            pd.read_csv(os.path.join(DATA_DIR, f'fold{i}.csv'))\n",
    "            for i in range(10) if i != fold\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        # build tf.data pipelines (with normalization baked in)\n",
    "        train_ds = make_dataset(train_df, training=True)\n",
    "        val_ds   = make_dataset(val_df,   training=False)\n",
    "\n",
    "        model = build_model(model_name)\n",
    "        ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "            f'{model_name}_fold{fold}.h5',\n",
    "            monitor='val_loss', save_best_only=True\n",
    "        )\n",
    "        hist = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[ckpt],\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        best = min(hist.history['val_loss'])\n",
    "        results_other[model_name].append(best)\n",
    "        print(f' Fold {fold} → best normalized-MSE: {best:.4f}')\n",
    "\n",
    "print('\\nCV normalized-MSE for remaining models:')\n",
    "for m, vals in results_other.items():\n",
    "    print(f' {m}:', [f'{v:.4f}' for v in vals])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423eb5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== inceptionv3 | Fold 0 ===\n",
      "Epoch 1/5\n",
      "354/354 - 46s - loss: 0.2670 - mae: 0.3839 - val_loss: 0.1522 - val_mae: 0.2834\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1178 - mae: 0.2565 - val_loss: 0.1325 - val_mae: 0.2768\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0778 - mae: 0.2102 - val_loss: 0.0868 - val_mae: 0.1975\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0587 - mae: 0.1817 - val_loss: 0.0841 - val_mae: 0.1920\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0430 - mae: 0.1548 - val_loss: 0.0712 - val_mae: 0.1797\n",
      "→ best normalized-MSE: 0.0712\n",
      "\n",
      "=== inceptionv3 | Fold 1 ===\n",
      "Epoch 1/5\n",
      "354/354 - 36s - loss: 0.2687 - mae: 0.3874 - val_loss: 0.1391 - val_mae: 0.2693\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1158 - mae: 0.2527 - val_loss: 0.1026 - val_mae: 0.2212\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0703 - mae: 0.1983 - val_loss: 0.0966 - val_mae: 0.2173\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0544 - mae: 0.1758 - val_loss: 0.1020 - val_mae: 0.2239\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0416 - mae: 0.1519 - val_loss: 0.0757 - val_mae: 0.1851\n",
      "→ best normalized-MSE: 0.0757\n",
      "\n",
      "=== inceptionv3 | Fold 2 ===\n",
      "Epoch 1/5\n",
      "354/354 - 36s - loss: 0.2591 - mae: 0.3808 - val_loss: 0.1291 - val_mae: 0.2630\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1110 - mae: 0.2495 - val_loss: 0.0920 - val_mae: 0.2131\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0762 - mae: 0.2048 - val_loss: 0.0765 - val_mae: 0.1955\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0497 - mae: 0.1655 - val_loss: 0.0784 - val_mae: 0.1856\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0394 - mae: 0.1471 - val_loss: 0.0765 - val_mae: 0.1930\n",
      "→ best normalized-MSE: 0.0765\n",
      "\n",
      "=== inceptionv3 | Fold 3 ===\n",
      "Epoch 1/5\n",
      "354/354 - 36s - loss: 0.2688 - mae: 0.3847 - val_loss: 0.1534 - val_mae: 0.3048\n",
      "Epoch 2/5\n",
      "354/354 - 29s - loss: 0.1113 - mae: 0.2493 - val_loss: 0.0818 - val_mae: 0.2052\n",
      "Epoch 3/5\n",
      "354/354 - 29s - loss: 0.0713 - mae: 0.1990 - val_loss: 0.0803 - val_mae: 0.2000\n",
      "Epoch 4/5\n",
      "354/354 - 29s - loss: 0.0589 - mae: 0.1799 - val_loss: 0.0633 - val_mae: 0.1810\n",
      "Epoch 5/5\n",
      "354/354 - 29s - loss: 0.0441 - mae: 0.1574 - val_loss: 0.0634 - val_mae: 0.1782\n",
      "→ best normalized-MSE: 0.0633\n",
      "\n",
      "=== inceptionv3 | Fold 4 ===\n",
      "Epoch 1/5\n",
      "354/354 - 37s - loss: 0.2751 - mae: 0.3898 - val_loss: 0.1786 - val_mae: 0.3194\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1253 - mae: 0.2647 - val_loss: 0.1183 - val_mae: 0.2568\n",
      "Epoch 3/5\n",
      "354/354 - 31s - loss: 0.0764 - mae: 0.2057 - val_loss: 0.1248 - val_mae: 0.2593\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0530 - mae: 0.1711 - val_loss: 0.0831 - val_mae: 0.1893\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0406 - mae: 0.1498 - val_loss: 0.0799 - val_mae: 0.1826\n",
      "→ best normalized-MSE: 0.0799\n",
      "\n",
      "=== inceptionv3 | Fold 5 ===\n",
      "Epoch 1/5\n",
      "354/354 - 36s - loss: 0.2722 - mae: 0.3871 - val_loss: 0.1107 - val_mae: 0.2492\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1166 - mae: 0.2545 - val_loss: 0.1013 - val_mae: 0.2423\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0820 - mae: 0.2148 - val_loss: 0.1003 - val_mae: 0.2289\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0596 - mae: 0.1830 - val_loss: 0.0654 - val_mae: 0.1833\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0428 - mae: 0.1547 - val_loss: 0.0654 - val_mae: 0.1784\n",
      "→ best normalized-MSE: 0.0654\n",
      "\n",
      "=== inceptionv3 | Fold 6 ===\n",
      "Epoch 1/5\n",
      "354/354 - 37s - loss: 0.2677 - mae: 0.3871 - val_loss: 0.1432 - val_mae: 0.2711\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1107 - mae: 0.2472 - val_loss: 0.1233 - val_mae: 0.2534\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0777 - mae: 0.2059 - val_loss: 0.0983 - val_mae: 0.2217\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0577 - mae: 0.1769 - val_loss: 0.0965 - val_mae: 0.2063\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0441 - mae: 0.1548 - val_loss: 0.0891 - val_mae: 0.2085\n",
      "→ best normalized-MSE: 0.0891\n",
      "\n",
      "=== inceptionv3 | Fold 7 ===\n",
      "Epoch 1/5\n",
      "354/354 - 37s - loss: 0.2554 - mae: 0.3752 - val_loss: 0.1314 - val_mae: 0.2550\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1148 - mae: 0.2531 - val_loss: 0.1166 - val_mae: 0.2474\n",
      "Epoch 3/5\n",
      "354/354 - 31s - loss: 0.0768 - mae: 0.2078 - val_loss: 0.0917 - val_mae: 0.2135\n",
      "Epoch 4/5\n",
      "354/354 - 33s - loss: 0.0493 - mae: 0.1672 - val_loss: 0.0879 - val_mae: 0.1888\n",
      "Epoch 5/5\n",
      "354/354 - 32s - loss: 0.0367 - mae: 0.1434 - val_loss: 0.0807 - val_mae: 0.1785\n",
      "→ best normalized-MSE: 0.0807\n",
      "\n",
      "=== inceptionv3 | Fold 8 ===\n",
      "Epoch 1/5\n",
      "354/354 - 37s - loss: 0.2738 - mae: 0.3891 - val_loss: 0.1470 - val_mae: 0.2762\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1232 - mae: 0.2620 - val_loss: 0.1220 - val_mae: 0.2488\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0765 - mae: 0.2080 - val_loss: 0.0931 - val_mae: 0.2059\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0544 - mae: 0.1753 - val_loss: 0.0923 - val_mae: 0.2100\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0404 - mae: 0.1527 - val_loss: 0.0817 - val_mae: 0.1868\n",
      "→ best normalized-MSE: 0.0817\n",
      "\n",
      "=== inceptionv3 | Fold 9 ===\n",
      "Epoch 1/5\n",
      "354/354 - 38s - loss: 0.2685 - mae: 0.3873 - val_loss: 0.1384 - val_mae: 0.2677\n",
      "Epoch 2/5\n",
      "354/354 - 30s - loss: 0.1181 - mae: 0.2547 - val_loss: 0.0935 - val_mae: 0.2159\n",
      "Epoch 3/5\n",
      "354/354 - 30s - loss: 0.0809 - mae: 0.2150 - val_loss: 0.0916 - val_mae: 0.2142\n",
      "Epoch 4/5\n",
      "354/354 - 30s - loss: 0.0575 - mae: 0.1792 - val_loss: 0.0940 - val_mae: 0.2064\n",
      "Epoch 5/5\n",
      "354/354 - 30s - loss: 0.0419 - mae: 0.1543 - val_loss: 0.0720 - val_mae: 0.1833\n",
      "→ best normalized-MSE: 0.0720\n",
      "\n",
      "InceptionV3 10-fold mean MSEₙ: 0.0755\n",
      "InceptionV3 10-fold mean RMSEₙ: 0.2749\n",
      "≈ 4.515655508964951 years off on average\n"
     ]
    }
   ],
   "source": [
    "# InceptionV3 across all 10 folds\n",
    "model_name = 'inceptionv3'\n",
    "results_inc = []\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f'\\n=== {model_name} | Fold {fold} ===')\n",
    "    # load CSVs\n",
    "    val_df = pd.read_csv(os.path.join(DATA_DIR, f'fold{fold}.csv'))\n",
    "    train_df = pd.concat([\n",
    "        pd.read_csv(os.path.join(DATA_DIR, f'fold{i}.csv'))\n",
    "        for i in range(10) if i != fold\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    # build tf.data pipelines (with your normalization baked in)\n",
    "    train_ds = make_dataset(train_df, training=True)\n",
    "    val_ds   = make_dataset(val_df,   training=False)\n",
    "\n",
    "    # build, train & checkpoint\n",
    "    model = build_model(model_name)\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'{model_name}_fold{fold}.h5',\n",
    "        monitor='val_loss', save_best_only=True\n",
    "    )\n",
    "    hist = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[ckpt],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # capture best normalized-MSE\n",
    "    best = min(hist.history['val_loss'])\n",
    "    results_inc.append(best)\n",
    "    print(f'→ best normalized-MSE: {best:.4f}')\n",
    "\n",
    "# Final summary\n",
    "import numpy as np\n",
    "mean_mse = np.mean(results_inc)\n",
    "mean_rmse = np.sqrt(mean_mse)\n",
    "print(f'\\nInceptionV3 10-fold mean MSEₙ: {mean_mse:.4f}')\n",
    "print(f'InceptionV3 10-fold mean RMSEₙ: {mean_rmse:.4f}')\n",
    "print('≈', mean_rmse * YEAR_STD, 'years off on average')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
